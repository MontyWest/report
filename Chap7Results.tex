%___________________________________________
%*************************************************************
% Results
%___________________________________________
%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

\section{Results}

%-----------------------------------------------------------------------
% Learning Results
%-----------------------------------------------------------------------

\subsection{Learning Data}

\afterpage{
\begin{landscape}
 \begin{figure}
  \centering
  \includegraphics[scale=0.6]{LearnGraph.png}
  \caption{Graph charting the best and average fitness over the LEMMEL learning run. Handcrafted \textbf{complex} agent fitness also included.}
  \label{fig:learngraph}
 \end{figure}
\end{landscape}
}

\begin{itemize}
\item Statistics output of learning module collated and organised.
\item Figure \ref{fig:learngraph} shows the data in graphical form. It includes the best and average fitness of each generation, with polynomial trend line.
\item Fitness of the handcrafted agent (on playing same levels) also included for comparison.
\item Agents evolved during this run are analysed in more detail in Section \ref{subsec:evallearnt}.
\end{itemize}

\subsubsection{Improvement over Time}

\begin{itemize}
\item Graph shows improvement in both average and best fitness.
\item During early generation improvement is rapid, but slows considerably after 200 generations.
\item Mainly due to agents saturating the evaluation task; 70,000 is a very high score, marking the completion of all levels. Anything over 60,000 is very capable agent (in terms of evaluation task).
\item We also see form the trend line that the best fitness is often better than the handcrafted complex agents fitness.
\end{itemize}

\clearpage

\subsubsection{Generation Variance}

\afterpage{
\begin{landscape}
\begin{figure}
	\centering
	\includegraphics[scale=0.6]{FixSeedGraph.png}
	\caption{A learning run which had a fixed level seed, performed in response to high generational variation in the LEMMEL run.}
	\label{fig:fixgraph}
\end{figure}
\end{landscape}
}

\begin{itemize}
\item It is evident from the graph that there is a lot of variance in both the best and average fitness between generations.
\item (Will include measurements of variance)
\item This could be explained by the rule based agent framework being sensitive to mutation, or the level playing module level seed affecting difficulty (explained further in Section \ref{sec:eval})
\item Due to this variance a learning run was performed that had a fixed level seed, so that each generation plays exactly the same levels, the graph is included as Figure \ref{fig:fixgraph}.
\item As expected (and due to the nature of $(\mu  + \lambda)$ ES) this removes all variance in the best fitness, but some still remains in average fitness.
\item Also the maximum fitness achieved by an agent in the run was higher.
\item (Graph also shows an issue with benchmark; non-determinism. The fitness jumps and falls at generation 882, this fitness calculation for the best agent was different between gen 882 and gen 883, and is unrepeatable in manual tests.)
\item The final agent produced from the fix seed run is included in the agent analysis below.
\end{itemize}

\subsubsection{Population Variance}

\begin{itemize}
\item Both graphs show a large difference between the best and average fitness. This suggest a large variance in fitness over a single population.
\item The last generation of the fix seed run has a standard deviation ...
\item As the ES ensures each generation's population are mutated from the previous best agents, this shows that the agent framework is particularly sensitive to mutation, which ruleset fitness dropping dramatically in one mutation round.
\item For example the final agent of the fixed seed run has a rule as such: ---- The worst agent of the final generation mutated (with only one mutation) this rule to: ---- Which instructed the agent to never move, causing a drop in score from 74xxx to 4xxx.
\end{itemize}

\clearpage
%-----------------------------------------------------------------------
% Learnt Agents
%-----------------------------------------------------------------------

\subsection{Handcrafted vs. Learnt Agent}
\label{subsec:evallearnt}

\begin{itemize}
\item Three learnt agents were taken from the learning runs to be analysed here: the Learnt Difference agent, which performed best compared to the average fitness (past generation 800); the Learnt Best agent, which got the highest fitness overall (past generation 800) and the Learnt Fixed Seed agent, which was the final agent from the fixed seed run.
\item This section will compare them with the handcrafted agents, in both the learning evaluation task and the comparator task (Section \ref{subsec:comptask}).
\end{itemize}

\subsubsection{Learning Evaluation Task}

\begin{table}
  \begin{adjustwidth}{-0cm}{-0cm}
  \begin{center} \small
    \begin{tabular}{ | l | c | c | c | c |}
    \hline
    \textbf{Agent} & \textbf{Average} & \textbf{Offset} & \textbf{Best} & \textbf{Worst} \TBstrut \\ \thickhline
    \textbf{Complex} & 59,206 & 0 & 74,286 & 38,494  \\ \hline
    \textbf{Simple Reactive} & 37,310 & 21,896 & 61,784 & 19,526 \\ \hline
    \textbf{Forward Jumping} & 20,458 & 38,748 & 45,022 & 8,378 \\ \thickhline
    \textbf{Learnt Best} & 59,079 & 127 & 73,058 & 43,740  \\ \hline
    \textbf{Learnt Difference} & 58,930 & 276 & 72,672 & 36,440  \\ \hline
    \textbf{Learnt Fixed Seed} & 54,115 & 5,091 & 74,194 & 38,494  \\ \hline
    \end{tabular}
  \end{center}
  \end{adjustwidth}
  \caption{\small Statistics from handcrafted and learnt agents playing each generation's evaluation task from the LEMMEL run.}
  \label{tab:learnrunagents}
\end{table}

\begin{itemize}
\item Three chosen learnt agents and three handcrafted agents were run through the each generation's evaluation task of the final learning task (i.e. 1000 tasks, with the same options, different seeds). Results are compiled in to Table \ref{tab:learnrunagents}
\item We can see from the data that both the Leant best and Learnt difference agents performed at the same level as the complex agent and considerable better than the other handcrafted agents. Which implies they became very capable at the task they were learning on.
\item We can also see that the learnt fixed seed agent did not perform quite as well, suggesting it became too suited to the single set of levels it was evolved over.
\item The large difference between best and worst fitness for each agent reiterates the problem of variance may stem from the level playing modules use of level seed, which may be overly affecting difficulty.
\end{itemize}

\clearpage
\subsubsection{Comparator Task}

\begin{table}
  \begin{adjustwidth}{-0cm}{-0cm}
  \begin{center} \small
    \begin{tabular}{ | l | c | c | c | c | c |}
    \hline
    & \textbf{Total} & \textbf{Levels} & \textbf{Enemies} & \Tstrut \\
    \textbf{Agent} & \textbf{Score} & \textbf{Completed} & \textbf{Killed} & \textbf{Distance} \Bstrut \\ \thickhline
    \textbf{Complex} & 1,758,931 & 168 (33\%) & 1,440 (8\%) & 62,231 (45\%) \\ \hline
    \textbf{Simple Reactive} & 1,102,733 & 87 (17\%) & 588 (3\%) & 44,038 (32\%) \\ \hline
    \textbf{Forward Jumping} & 954,141 & 65 (13\%) & 743 (4\%) & 38,484 (28\%) \\ \thickhline
    \textbf{Learnt Difference} & 1,521,200 & 144 (28\%) & 1,130 (6\%) & 55,710 (40\%) \\ \hline
    \textbf{Learnt Best} & 1,510,697 & 133 (26\%) & 1,603 (8\%) & 54,341 (39\%) \\ \hline
    \textbf{Learnt Fixed Seed} & 1,267,914 & 102 (20\%) & 1,173 (6\%) & 48,131 (35\%) \\ \hline
    \end{tabular}
  \end{center}
  \end{adjustwidth}
  \caption{\small Competitive statistics from handcrafted and learnt agents playing the comparator task with a seed of 1000.}
  \label{tab:learnagentcomp}
\end{table}

\afterpage{
\begin{landscape}
 \begin{figure}
  \centering
  \includegraphics[scale=0.5]{CompTaskGraph.png}
  \caption{Graph charting the score achieved on different difficulty levels during the comparator task.}
  \label{fig:compgraph}
 \end{figure}
\end{landscape}
}

\begin{itemize}
\item Three chosen learnt agents and three handcrafted agents were run through the comparator task with seed of 1000. Results are compiled in to Table \ref{tab:learnagentcomp}
\item We can see from the data that both the Leant best and Learnt difference agents performed better than the two simpler handcrafted agents, but not as well as the complex agent. Considering the evaluation task result, this shows that the learning evaluation task it doesn't represent the comparator task well enough
\item We can also see that the learnt fixed seed agent did not perform quite as well, suggesting learning from many sets of levels helps when tackling different challenges.
\item Figure \ref{fig:compgraph} shows how the agents performed at different difficulties in the comparator task. Learnt agents were outperformed by complex agent on all difficulties (especially 6, 5 and 4) except 2, which was the most prevalent in the learning evaluation task. Implying that a longer and more representative task may produce a better agent.
\end{itemize}

\clearpage
%-----------------------------------------------------------------------
% Learnt Agent Behaviours
%-----------------------------------------------------------------------
\subsection{Learnt Agent Analysis}
\label{subsec:evallearn2}

\begin{table}[!t]
  \begin{adjustwidth}{-2cm}{-2cm}
  \begin{center} \scriptsize
    \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | c | c || c | c | c | c |}
    \hline
    \multirow{2}{*}{\textbf{\#}} & \multicolumn{11}{c ||}{\textbf{Conditions}} & \multicolumn{4}{c |}{\textbf{Actions}} \Tstrut \\ \cline{2-16}
    
	& \tiny MM & \tiny JA & \tiny OG & \tiny EL & \tiny EUR & \tiny ELR & \tiny OA & \tiny PA & \tiny PB & \tiny MX & \tiny MY & \tiny Left~ & \tiny Right & \tiny Jump~ & \tiny Speed \TBstrut \\ \thickhline
	1 & & & 1 & & 1 & 1 & & 0 & 1 & 2 & 0 		& & & T & T \\ \hline
	2 & & 0 & & & & & & & & 2 & 2		& & T & T & T \\ \hline
	3 & & 1 & & & 1 & & 1 & & 0 & & 0 		& & & T & T \\ \hline
	4 & & 0 & 0 & & & 0 & 1 & 0 & 1 & 0 & 1 		& T & T & T & T \\ \hline
	5 & & & & & 0 & 0 & 1 & & 0 & 0 & 0 		& & & T & \\ \hline
	6 & & 0 & & & 1 & 1 & 1 & & 0 & 0 & 		& & & T & T \\ \hline
	7 & & 1 & 0 & & & 0 & & 0 & 0 & & 2 		& & & & \\ \hline
	8 & & & & 0 & 0 & 0 & 0 & & 1 & 2 & 1		& & T & T & T \\ \hline
	9 & & & & & & & & & 0 & 0 & 2 		& & & T & \\ \hline
	10 & & 0 & 1 & & & & 1 & 1 & & 0 & 		& & & & \\ \hline
	11 & 0 & & 1 & 1 & 0 & 1 & & 1 & 0 & & 1 		& & T & & T \\ \hline
	12 & & & & & 1 & & & 2 & & & 		& & & & T \\ \hline
	13 & & & & & & & 0 & & 0 & 2 & 1 		& T & & T & T \\ \hline
	14 & & 1 & 0 & 1 & 0 & 1 & 1 & 0 & & 0 & 		& T & T & T & T \\ \hline
	15 & & 1 & & & & & & & 1 & 0 & 2 		& T & T & T & T \\ \hline
	16 & & 1 & 1 & 0 & & & & 1 & & & 		& T & T & T & \\ \hline
	17 & & 1 & 1 & & 0 & & & & 1 & & 0 		& & T & T & T \\ \hline
	18 & & 1 & 1 & & & 1 & & 0 & & & 		& & & T & \\ \hline
	19 & & 1 & & & 1 & & & 2 & 0 & & 0 		& T & & & T \\ \hline
	20 & & & 0 & & & 0 & 0 & & 0 & 0 & 0 		& T & T & T & T \\ \hline
		
	-  & & & & & & & & & & & 		& & T & & T \\ \hline
    \end{tabular}
  \end{center}
  \end{adjustwidth}
  \caption{Ruleset for learnt difference agent. Blank entries denote {\scriptsize DONT\_CARE} for Conditions and \textbf{false} for Actions. A key for this table can be found in Appendix \ref{app:percond}}
  \label{tab:LDA}
\end{table}

\begin{itemize}
\item Of the learnt agents the learnt difference agent performs the best in the comparator task
\item It also displays the most interesting behaviour which will be discussed here
\item A full ruleset for this agent is included in Figure \ref{tab:LDA} 
\end{itemize}

\subsubsection{Rule usage}

\begin{itemize}
\item The agent only regularly uses 7 of its 20 rules, and relies heavily on the default action.
\item Suggests mutation strategy might be too simplistic for ruleset genome.
\end{itemize}

\subsubsection{Behaviours}

\begin{itemize}
\item The agent acts similarly to the complex and simple reactive agent. It jumps over pits, obstacles and enemies.
\item Four behaviours are presented in depth below. 
\end{itemize}

\subsubsection*{\hspace{6pt}Obstacles}

\begin{figure}[t]
	\begin{adjustwidth}{-2cm}{-2cm}
    \centering
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laob1.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laob2.png}
                  \caption{Rule 5}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laob3.png}
                  \caption{Rule 9}
          \end{subfigure}
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laob4.png}
                  \caption{Rule 9}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laob5.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laob6.png}
                  \caption{Default Rule}
          \end{subfigure}
    \caption{Learnt Difference agent tackling obstacles, without over-jumping.}\label{fig:laob}
    \end{adjustwidth}
\end{figure}

\begin{itemize}
\item Most interesting, seen on most learnt agents.
\item Evolved early, generation 50 or so.
\item Uses rules 5 and 9 to jump over obstacles. But only when Mario is stationary.
\item This is very useful for stairs (obstacles before pits) as the agent avoids jumping into the pit, something common with the simple reactive agent.
\item Figure \ref{fig:laob} shows this process. Agent runs until he hits the wall, activates rule 5 to jump, rule 9 keeps the jump until top height, when coming down uses default rule to move right.
\item This is an example of a behaviour not considered in handcrafting, as the complex agent solves this problem differently.
\end{itemize}

\clearpage
\subsubsection*{\hspace{6pt}Pits}

\begin{figure}[t]
	\begin{adjustwidth}{-2cm}{-2cm}
    \centering
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{lapj1.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{lapj2.png}
                  \caption{Rule 16}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{lapj3.png}
                  \caption{Rule 2}
          \end{subfigure}
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{lapj4.png}
                  \caption{Rule 8}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{lapj5.png}
                  \caption{Rule 13}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{lapj6.png}
                  \caption{Default Rule}
          \end{subfigure}
    \caption{Learnt Difference agent tackling pits, without over-jumping.}\label{fig:lapj}
    \end{adjustwidth}
\end{figure}


\begin{itemize}
\item Similar but not equivalent system seen on most learnt agents.
\item Uses rules 16, 2, 8, 13 to jump over pits and land on the very edge of the other side.
\item This is useful as Mario avoids falling in a proceeding pit or touching an enemy.
\item Figure \ref{fig:lapj} shows this process. Agent uses obstacle behaviour to climb the stairs. Then uses rule 16 to begin the jump, Rule 2 moves the agent forward at speed when moving up, Rule 8 continues this action as he moves down. When over the pit Rule 13 ensures he doesn't go too far by moving him left until he touches the ground.
\end{itemize}


\clearpage
\subsubsection*{\hspace{6pt}Enemies}

\begin{figure}[t]
	\begin{adjustwidth}{-2cm}{-2cm}
    \centering
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laej1.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laej2.png}
                  \caption{Rule 18}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laej3.png}
                  \caption{Rule 2}
          \end{subfigure}
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laej4.png}
                  \caption{Rule 13}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laej5.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laej6.png}
                  \caption{Default Rule}
          \end{subfigure}
    \caption{Learnt Difference agent tackling enemies.}\label{fig:laej}
    \end{adjustwidth}
\end{figure}


\begin{itemize}
\item Similar but not equivalent system seen on most learnt agents.
\item Uses rules 18, 2, and 13 to jump over enemies and clear the landing zone with a fireball.
\item Figure \ref{fig:laej} shows this process. Agent approaches an enemy and uses rule 18 to jump, Rule 2 continues the jump and fires a fireball (if in fire mode). This fireball beats Mario to the landing zone, where it can clear enemies.
\end{itemize}


\clearpage
\subsubsection*{\hspace{6pt}Pits with Enemies}

\begin{figure}[t]
	\begin{adjustwidth}{-2cm}{-2cm}
    \centering
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laepa1.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laepa2.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laepa3.png}
                  \caption{Rule 19}
          \end{subfigure}
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laepa4.png}
                  \caption{Rule 19}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laepa5.png}
                  \caption{Default Rule}
          \end{subfigure}~
          \begin{subfigure}[b]{0.328\textwidth}
                  \centering
                  \includegraphics[width=\textwidth]{laepa6.png}
                  \caption{Rule 16}
          \end{subfigure}
    \caption{Learnt Difference agent tackling pits where enemies are blocking the jump.}\label{fig:laepa}
    \end{adjustwidth}
\end{figure}


\begin{itemize}
\item An advanced behaviour that is not seen in other agents.
\item Uses rule 19 to avoiding jumping into enemies when clearing pits.
\item Figure \ref{fig:laepa} shows this process. Agent approaches an pit and if there is an enemy blocking the jump, it turns around and moves away. When the enemy moves or falls agent jumps the pit.
\end{itemize}

