%___________________________________________
%*************************************************************
% Evaluation
%___________________________________________
%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

\section{Evaluation}

With the result presented above we can now critically consider the project in terms of the requirements set out in the project's aim, objectives (Section \ref{subsec:aimobj}) and specification (Section \ref{sec:projspec}).

%-----------------------------------------------------------------------
% Agent Framework
%-----------------------------------------------------------------------

\subsection{Agent Framework}

The primary objective of the agent framework was to enable and encourage meaningful improvement during learning. The focus on a rule based system allowed for agents to be represented with a simple encoding, which afforded a great deal of freedom to the learning module. It reduced development time as several features of the ECJ library could be used as is and any extensions did not have to process a complex data structure. Moreover, it allowed for more greater control, which was crucial in honing and revising the learning parameters. Ultimately, we can see from the results that, given the right parameters, the agent framework did enable significant improvement over generation, with later agents achieving near maximum fitness.

Additionally, there were three criteria laid out for the agent's use of a rule based system in Section \ref{sec:projspec}: speed, capability and complexity. The framework design relies heavily on how the agent senses the environment; as such the selection of perceptions is a major factor in its evaluation.

The \textbf{complex} handcrafted ruleset shows that the framework's choice of perceptions allows for capable agents. It rarely fails to finish the easier levels and can successfully tackle some of the more difficult challenges. Furthermore, the depth of the perceptions and the available actions allows for competent behaviour to be demonstrated by relatively small rulesets, which improves the agent's speed. In fact, agent response time never rises above a millisecond. This allows for levels to be run at practically any number of frames per second and has little effect on total learning time.

On the other hand, the framework is still limited. There is no way for any ruleset agent to break itself out of a loop or navigate a dead end. Similarly, it can never develop an effective enemy killing behaviour without differentiate between different types.

However, as discussed in Section \ref{subsec:agentdes}, improving capability by embellishing the agent's perceptions comes at the penalty of complexity. A more complex design lends to a larger search space for the learning algorithm, which hinders the development of a successful agent through random mutation. This was also a crucial consideration of the REALM team, whose V2 agent was designed, in part, to reduce the search space of the VI agent \cite{realm}[p.~86].

In its current form, the agent framework balances these factors reasonably well. Our results show that a successful and interesting agent can be evolved despite the total number of possible rules
\[ \centering
4^4 * 3^7 * 2^4 = 8,957,952
\]
being higher than that of REALM's V1 agent ($7,558,272$) \cite{realm}[p.~86]. Thus, improvements to the capability of the agent should not increase the search space, but instead focus on making each perception is purposeful.

In the final set of parameters (and in the handcrafted agents) we encouraged the disregarding of the MarioMode and EnemyLeft perceptions. Our learning parameters allowed us to reduce the search space by increasing the probability of the {\footnotesize DONT\_CARE} condition. This is clearly a counter intuitive approach and the agent design should be amended by removing these perceptions. 

Such removal would allow for additional perceptions and/or design extensions without increasing agent complexity. Given more time, a redesign that allowed agent encoding control over its perceptions would be considered. Perceptions would remain fixed, but the parameters that control them would be variable. For example, the area in which an agent looks for an obstacle or enemy could be controlled by parameters on a ruleset wide basis. Moreover, perceptions that ascertain the last used action (a simplistic form of memory) and greater detail in the identifying enemies would also be investigated.

\subsection{Level Playing}

%-----------------------------------------------------------------------
% Level playing
%-----------------------------------------------------------------------

\subsection{Level Playing}

%-----------------------------------------------------------------------
% Learning Process
%-----------------------------------------------------------------------

\subsection{Learning Process}



%-----------------------------------------------------------------------
% Project Evaluation
%-----------------------------------------------------------------------

\subsection{Methodolgy}